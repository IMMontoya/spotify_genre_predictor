{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Pudding 2024\n",
    "***\n",
    "\n",
    "The purpose of this notebook will be to analyse data retrieved from the [Spotify Web API](https://developer.spotify.com/documentation/web-api) in order to train various machine learning models to predict the genre of any given song. Once the models have been trained, validated and tested, a function will be built that feeds the data from the API to the best preforming model, and it's genre will be predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'spotify_data_more.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspotify_data_more.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m data\u001b[38;5;241m.\u001b[39minfo()\n",
      "File \u001b[1;32mc:\\Users\\m-gle\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\m-gle\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\m-gle\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\m-gle\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\m-gle\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'spotify_data_more.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('spotify_data_more.csv', index_col='track_id')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9000 entries, 44AyOl4qVkzS48vBsbNXaC to 3tHCG0ISOA0pXscIdNrJml\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   genre             9000 non-null   object \n",
      " 1   danceability      9000 non-null   float64\n",
      " 2   energy            9000 non-null   float64\n",
      " 3   key               9000 non-null   int64  \n",
      " 4   loudness          9000 non-null   float64\n",
      " 5   mode              9000 non-null   int64  \n",
      " 6   speechiness       9000 non-null   float64\n",
      " 7   acousticness      9000 non-null   float64\n",
      " 8   instrumentalness  9000 non-null   float64\n",
      " 9   liveness          9000 non-null   float64\n",
      " 10  valence           9000 non-null   float64\n",
      " 11  tempo             9000 non-null   float64\n",
      " 12  duration_ms       9000 non-null   int64  \n",
      " 13  time_signature    9000 non-null   int64  \n",
      "dtypes: float64(9), int64(4), object(1)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(['type', 'uri', 'track_href', 'analysis_url'], axis=1)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8100, 14)\n",
      "(900, 14)\n",
      "(8100, 13) (8100,)\n",
      "(900, 13) (900,)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, random_state=42)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "X_train = train.drop(['genre'], axis=1)\n",
    "y_train = train['genre']\n",
    "X_test = test.drop(['genre'], axis=1)\n",
    "y_test = test['genre']\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing KFold Instance\n",
    "cross_validator = KFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DummyClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m dummy_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrategy\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmost_frequent\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprior\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstratified\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrock\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m }\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Initializing DummyClassifier and its GridSearchCV\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m dummy_model \u001b[38;5;241m=\u001b[39m DummyClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      9\u001b[0m dummy_grid_roc_auc \u001b[38;5;241m=\u001b[39m GridSearchCV(dummy_model, dummy_params, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc_ovo_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39mcross_validator)\n\u001b[0;32m     10\u001b[0m dummy_grid_f1 \u001b[38;5;241m=\u001b[39m GridSearchCV(dummy_model, dummy_params, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39mcross_validator)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DummyClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Creating Dummy model param grid\n",
    "dummy_params = {\n",
    "    'strategy':['most_frequent', 'prior', 'stratified', 'uniform', 'constant'],\n",
    "    'constant':['rock']\n",
    "}\n",
    "\n",
    "# Initializing DummyClassifier and its GridSearchCV\n",
    "dummy_model = DummyClassifier(random_state=42)\n",
    "dummy_grid_roc_auc = GridSearchCV(dummy_model, dummy_params, scoring='roc_auc_ovo_weighted', cv=cross_validator)\n",
    "dummy_grid_f1 = GridSearchCV(dummy_model, dummy_params, scoring='f1_weighted', cv=cross_validator)\n",
    "\n",
    "# Training Grid\n",
    "dummy_grid_roc_auc.fit(X_train, y_train)\n",
    "dummy_grid_f1.fit(X_train, y_train)\n",
    "dummy_f1 = cross_val_score(dummy_grid_roc_auc.best_estimator_, X_train, y_train, scoring='f1_weighted', cv=cross_validator).mean()\n",
    "dummy_roc_auc = cross_val_score(dummy_grid_f1.best_estimator_, X_train, y_train, scoring='roc_auc_ovo_weighted', cv=cross_validator).mean()\n",
    "\n",
    "roc_auc_curve = metrics.RocCurveDisplay.from_estimator(dummy_grid_roc_auc.best_estimator_, X_train, y_train)\n",
    "f1_curve = metrics.RocCurveDisplay.from_estimator(dummy_grid_f1.best_estimator_)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(dummy_grid_roc_auc.best_estimator_, f'ROC_AUC: {dummy_grid_roc_auc.best_score_}')\n",
    "print('F1 of ROC_AUC model: ', dummy_f1, '\\n')\n",
    "print(dummy_grid_f1.best_estimator_, f'F1: {dummy_grid_f1.best_score_}')\n",
    "print('ROC_AUC of F1 model: ', dummy_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=7, min_samples_split=6, random_state=42) ROC_AUC: 0.7844794389067227\n",
      "F1 of ROC_AUC model:  0.48894107684397276 \n",
      "\n",
      "DecisionTreeClassifier(max_depth=9, min_samples_split=6, random_state=42) F1: 0.49247320622517093\n",
      "ROC_AUC of F1 model:  0.7702834658469125\n"
     ]
    }
   ],
   "source": [
    "# Creating DecisionTree model param grid\n",
    "tree_params = {\n",
    "    'max_depth':np.arange(3, 11, 1),\n",
    "    'min_samples_split':[2,4,6]\n",
    "}\n",
    "\n",
    "# Initializing DecisionTree and its GridSearchCV\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "tree_grid_roc_auc = GridSearchCV(tree_model, tree_params, scoring='roc_auc_ovo_weighted', cv=cross_validator)\n",
    "tree_grid_f1 = GridSearchCV(tree_model, tree_params, scoring='f1_weighted', cv=cross_validator)\n",
    "\n",
    "# Training Grid\n",
    "tree_grid_roc_auc.fit(X_train, y_train)\n",
    "tree_grid_f1.fit(X_train, y_train)\n",
    "tree_f1 = cross_val_score(tree_grid_roc_auc.best_estimator_, X_train, y_train, scoring='f1_weighted', cv=cross_validator).mean()\n",
    "tree_roc_auc = cross_val_score(tree_grid_f1.best_estimator_, X_train, y_train, scoring='roc_auc_ovo_weighted', cv=cross_validator).mean()\n",
    "\n",
    "print(tree_grid_roc_auc.best_estimator_, f'ROC_AUC: {tree_grid_roc_auc.best_score_}')\n",
    "print('F1 of ROC_AUC model: ', tree_f1, '\\n')\n",
    "print(tree_grid_f1.best_estimator_, f'F1: {tree_grid_f1.best_score_}')\n",
    "print('ROC_AUC of F1 model: ', tree_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=22, n_estimators=1500, random_state=42) ROC_AUC: 0.8656457394367386\n",
      "F1 of ROC_AUC model:  0.5755083909317781 \n",
      "\n",
      "RandomForestClassifier(max_depth=22, n_estimators=1500, random_state=42) F1: 0.5755083909317781\n",
      "ROC_AUC of F1 model:  0.7702834658469125\n"
     ]
    }
   ],
   "source": [
    "# Creating RandomForest model param grid\n",
    "forest_params = {\n",
    "    'n_estimators':[500, 1000, 1500],\n",
    "    'max_depth':np.arange(20, 41, 2),\n",
    "}\n",
    "\n",
    "# Initializing RandomForest and its GridSearchCV\n",
    "forest_model = RandomForestClassifier(random_state=42)\n",
    "forest_grid_roc_auc = GridSearchCV(forest_model, forest_params, scoring='roc_auc_ovo_weighted', cv=cross_validator)\n",
    "forest_grid_f1 = GridSearchCV(forest_model, forest_params, scoring='f1_weighted', cv=cross_validator)\n",
    "\n",
    "# Training Grid\n",
    "forest_grid_roc_auc.fit(X_train, y_train)\n",
    "forest_grid_f1.fit(X_train, y_train)\n",
    "forest_f1 = cross_val_score(forest_grid_roc_auc.best_estimator_, X_train, y_train, scoring='f1_weighted', cv=cross_validator).mean()\n",
    "forest_roc_auc = cross_val_score(forest_grid_f1.best_estimator_, X_train, y_train, scoring='roc_auc_ovo_weighted', cv=cross_validator).mean()\n",
    "\n",
    "print(forest_grid_roc_auc.best_estimator_, f'ROC_AUC: {forest_grid_roc_auc.best_score_}')\n",
    "print('F1 of ROC_AUC model: ', forest_f1, '\\n')\n",
    "print(forest_grid_f1.best_estimator_, f'F1: {forest_grid_f1.best_score_}')\n",
    "print('ROC_AUC of F1 model: ', forest_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.01, num_leaves=100, random_state=42,\n",
      "               verbosity=-1) ROC_AUC: 0.8431479275343451\n",
      "F1 of ROC_AUC model:  0.5523200542615104 \n",
      "\n",
      "LGBMClassifier(learning_rate=0.01, num_leaves=200, random_state=42,\n",
      "               verbosity=-1) F1: 0.5565323696002716\n",
      "ROC_AUC of F1 model:  0.8430191651830828\n"
     ]
    }
   ],
   "source": [
    "# Creating LightGBM model param grid\n",
    "lightgbm_params = {\n",
    "    'num_leaves':[31, 100, 200],\n",
    "    'learning_rate':[0.01]\n",
    "}\n",
    "\n",
    "# Initializing LightGBM and its GridSearchCV\n",
    "lightgbm_model = lgb.LGBMClassifier(random_state=42, verbosity=-1)\n",
    "lightgbm_grid_roc_auc = GridSearchCV(lightgbm_model, lightgbm_params, scoring='roc_auc_ovo_weighted', cv=cross_validator)\n",
    "lightgbm_grid_f1 = GridSearchCV(lightgbm_model, lightgbm_params, scoring='f1_weighted', cv=cross_validator)\n",
    "\n",
    "# Training Grid\n",
    "lightgbm_grid_roc_auc.fit(X_train, y_train)\n",
    "lightgbm_grid_f1.fit(X_train, y_train)\n",
    "lightgbm_f1 = cross_val_score(lightgbm_grid_roc_auc.best_estimator_, X_train, y_train, scoring='f1_weighted', cv=cross_validator).mean()\n",
    "lightgbm_roc_auc = cross_val_score(lightgbm_grid_f1.best_estimator_, X_train, y_train, scoring='roc_auc_ovo_weighted', cv=cross_validator).mean()\n",
    "\n",
    "print(lightgbm_grid_roc_auc.best_estimator_, f'ROC_AUC: {lightgbm_grid_roc_auc.best_score_}')\n",
    "print('F1 of ROC_AUC model: ', lightgbm_f1, '\\n')\n",
    "print(lightgbm_grid_f1.best_estimator_, f'F1: {lightgbm_grid_f1.best_score_}')\n",
    "print('ROC_AUC of F1 model: ', lightgbm_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.7825969\ttotal: 10.6ms\tremaining: 10.6s\n",
      "1000:\tlearn: 0.9863546\ttotal: 9.21s\tremaining: 0us\n",
      "0:\tlearn: 1.7827187\ttotal: 44.7ms\tremaining: 44.7s\n",
      "1000:\tlearn: 0.9912005\ttotal: 9.07s\tremaining: 0us\n",
      "0:\tlearn: 1.7832833\ttotal: 42.1ms\tremaining: 42.1s\n",
      "1000:\tlearn: 0.9852248\ttotal: 9.09s\tremaining: 0us\n",
      "0:\tlearn: 1.7825969\ttotal: 16.8ms\tremaining: 33.7s\n",
      "1000:\tlearn: 0.9863546\ttotal: 9s\tremaining: 8.99s\n",
      "2000:\tlearn: 0.8357130\ttotal: 17.9s\tremaining: 0us\n",
      "0:\tlearn: 1.7827187\ttotal: 10.3ms\tremaining: 20.5s\n",
      "1000:\tlearn: 0.9912005\ttotal: 9.01s\tremaining: 9s\n",
      "2000:\tlearn: 0.8355803\ttotal: 18s\tremaining: 0us\n",
      "0:\tlearn: 1.7832833\ttotal: 33.8ms\tremaining: 1m 7s\n",
      "1000:\tlearn: 0.9852248\ttotal: 9.13s\tremaining: 9.13s\n",
      "2000:\tlearn: 0.8346204\ttotal: 19.2s\tremaining: 0us\n",
      "0:\tlearn: 1.7820866\ttotal: 13.9ms\tremaining: 27.8s\n",
      "1000:\tlearn: 1.0167922\ttotal: 9.78s\tremaining: 9.77s\n",
      "2000:\tlearn: 0.8863225\ttotal: 20.9s\tremaining: 0us\n",
      "0:\tlearn: 1.7825969\ttotal: 50.1ms\tremaining: 50.1s\n",
      "1000:\tlearn: 0.9863546\ttotal: 9.36s\tremaining: 0us\n",
      "0:\tlearn: 1.7827187\ttotal: 10.5ms\tremaining: 10.5s\n",
      "1000:\tlearn: 0.9912005\ttotal: 9.15s\tremaining: 0us\n",
      "0:\tlearn: 1.7832833\ttotal: 14.6ms\tremaining: 14.6s\n",
      "1000:\tlearn: 0.9852248\ttotal: 9.09s\tremaining: 0us\n",
      "0:\tlearn: 1.7825969\ttotal: 11.5ms\tremaining: 22.9s\n",
      "1000:\tlearn: 0.9863546\ttotal: 9.07s\tremaining: 9.06s\n",
      "2000:\tlearn: 0.8357130\ttotal: 18s\tremaining: 0us\n",
      "0:\tlearn: 1.7827187\ttotal: 41.7ms\tremaining: 1m 23s\n",
      "1000:\tlearn: 0.9912005\ttotal: 10.3s\tremaining: 10.3s\n",
      "2000:\tlearn: 0.8355803\ttotal: 19.3s\tremaining: 0us\n",
      "0:\tlearn: 1.7832833\ttotal: 16.1ms\tremaining: 32.2s\n",
      "1000:\tlearn: 0.9852248\ttotal: 9.18s\tremaining: 9.17s\n",
      "2000:\tlearn: 0.8346204\ttotal: 18.1s\tremaining: 0us\n",
      "0:\tlearn: 1.7820866\ttotal: 12.4ms\tremaining: 24.8s\n",
      "1000:\tlearn: 1.0167922\ttotal: 10.1s\tremaining: 10.1s\n",
      "2000:\tlearn: 0.8863225\ttotal: 19.7s\tremaining: 0us\n",
      "0:\tlearn: 1.7825969\ttotal: 12.4ms\tremaining: 24.8s\n",
      "1000:\tlearn: 0.9863546\ttotal: 9.01s\tremaining: 9s\n",
      "2000:\tlearn: 0.8357130\ttotal: 18s\tremaining: 0us\n",
      "0:\tlearn: 1.7827187\ttotal: 31.7ms\tremaining: 1m 3s\n",
      "1000:\tlearn: 0.9912005\ttotal: 9.58s\tremaining: 9.57s\n",
      "2000:\tlearn: 0.8355803\ttotal: 19s\tremaining: 0us\n",
      "0:\tlearn: 1.7832833\ttotal: 17.4ms\tremaining: 34.8s\n",
      "1000:\tlearn: 0.9852248\ttotal: 9s\tremaining: 8.99s\n",
      "2000:\tlearn: 0.8346204\ttotal: 18.3s\tremaining: 0us\n",
      "0:\tlearn: 1.7825969\ttotal: 10.5ms\tremaining: 21.1s\n",
      "1000:\tlearn: 0.9863546\ttotal: 9.82s\tremaining: 9.81s\n",
      "2000:\tlearn: 0.8357130\ttotal: 18.6s\tremaining: 0us\n",
      "0:\tlearn: 1.7827187\ttotal: 25ms\tremaining: 50s\n",
      "1000:\tlearn: 0.9912005\ttotal: 9.06s\tremaining: 9.05s\n",
      "2000:\tlearn: 0.8355803\ttotal: 17.8s\tremaining: 0us\n",
      "0:\tlearn: 1.7832833\ttotal: 15.6ms\tremaining: 31.2s\n",
      "1000:\tlearn: 0.9852248\ttotal: 9.08s\tremaining: 9.07s\n",
      "2000:\tlearn: 0.8346204\ttotal: 18.1s\tremaining: 0us\n",
      "<catboost.core.CatBoostClassifier object at 0x0000019CE5FA1810> ROC_AUC: 0.8602144547482479\n",
      "F1 of ROC_AUC model:  0.566502298583798 \n",
      "\n",
      "<catboost.core.CatBoostClassifier object at 0x0000019CE82BBB50> F1: 0.566502298583798\n",
      "ROC_AUC of F1 model:  0.8602144547482479\n"
     ]
    }
   ],
   "source": [
    "# Creating CatBoost model param grid\n",
    "catboost_params = {\n",
    "    'iterations':[1001, 2001],\n",
    "    'learning_rate':[0.01]\n",
    "}\n",
    "\n",
    "# Initializing CatBoost and its GridSearchCV\n",
    "catboost_model = CatBoostClassifier(random_seed=42, verbose=1000)\n",
    "catboost_grid_roc_auc = GridSearchCV(catboost_model, catboost_params, scoring='roc_auc_ovo_weighted', cv=cross_validator)\n",
    "catboost_grid_f1 = GridSearchCV(catboost_model, catboost_params, scoring='f1_weighted', cv=cross_validator)\n",
    "\n",
    "# Training Grid\n",
    "catboost_grid_roc_auc.fit(X_train, y_train)\n",
    "catboost_grid_f1.fit(X_train, y_train)\n",
    "catboost_f1 = cross_val_score(catboost_grid_roc_auc.best_estimator_, X_train, y_train, scoring='f1_weighted', cv=cross_validator).mean()\n",
    "catboost_roc_auc = cross_val_score(catboost_grid_f1.best_estimator_, X_train, y_train, scoring='roc_auc_ovo_weighted', cv=cross_validator).mean()\n",
    "\n",
    "\n",
    "print(catboost_grid_roc_auc.best_estimator_, f'ROC_AUC: {catboost_grid_roc_auc.best_score_}')\n",
    "print('F1 of ROC_AUC model: ', catboost_f1, '\\n')\n",
    "print(catboost_grid_f1.best_estimator_, f'F1: {catboost_grid_f1.best_score_}')\n",
    "print('ROC_AUC of F1 model: ', catboost_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=22, n_estimators=1500, random_state=42) Test ROC_AUC: 0.8818380990339227\n",
      "F1 of ROC_AUC model:  0.6007459537175455 \n",
      "\n",
      "RandomForestClassifier(max_depth=22, n_estimators=1500, random_state=42) Test F1: 0.6007459537175455\n",
      "ROC_AUC of F1 model:  0.8818380990339227\n"
     ]
    }
   ],
   "source": [
    "test_roc_auc_predict = forest_grid_roc_auc.best_estimator_.predict(X_test)\n",
    "test_roc_auc_proba = forest_grid_roc_auc.best_estimator_.predict_proba(X_test)\n",
    "test_f1_predict = forest_grid_f1.best_estimator_.predict(X_test)\n",
    "test_f1_proba = forest_grid_f1.best_estimator_.predict_proba(X_test)\n",
    "\n",
    "test_roc_auc = metrics.roc_auc_score(y_test, test_roc_auc_proba, average='weighted', multi_class='ovo')\n",
    "test_roc_auc_f1 = metrics.f1_score(y_test, test_roc_auc_predict, average='weighted')\n",
    "test_f1 = metrics.f1_score(y_test, test_f1_predict, average='weighted')\n",
    "test_f1_roc_auc = metrics.roc_auc_score(y_test, test_f1_proba, average='weighted', multi_class='ovo')\n",
    "    \n",
    "\n",
    "\n",
    "print(forest_grid_roc_auc.best_estimator_, f'Test ROC_AUC: {test_roc_auc}')\n",
    "print('F1 of ROC_AUC model: ', test_roc_auc_f1, '\\n')\n",
    "print(forest_grid_f1.best_estimator_, f'Test F1: {test_f1}')\n",
    "print('ROC_AUC of F1 model: ', test_f1_roc_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
