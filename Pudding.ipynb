{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Pudding 2024\n",
    "***\n",
    "\n",
    "The purpose of this notebook will be to analyse data retrieved from the [Spotify Web API](https://developer.spotify.com/documentation/web-api) in order to train various machine learning models to predict the genre of any given song. Once the models have been trained, validated and tested, a function will be built that feeds the data from the API to the best preforming model, and it's genre will be predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "### Spotify API Setup and Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the client_id and client_secret from environment variables\n",
    "client_id = os.getenv(\"Client_ID\")\n",
    "client_secret = os.getenv(\"Client_secret\")\n",
    "\n",
    "# Authentication\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager, requests_timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase timeout and add retry logic\n",
    "session = sp._session\n",
    "retry = Retry(\n",
    "    total=5,  # Total number of retries\n",
    "    backoff_factor=0.3,  # Wait time between retries\n",
    "    status_forcelist=[500, 502, 503, 504],  # Retry on these HTTP status codes\n",
    "    raise_on_status=False\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry)  # Increase timeout to 10 seconds\n",
    "session.mount(\"https://\", adapter)\n",
    "\n",
    "# Set random seed\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_genre_string(genre, debug=False):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        genre: str, genre string to test\n",
    "        debug: bool, print debug messages\n",
    "    Output:\n",
    "        bool: True if the genre is valid, False if not\n",
    "        \n",
    "    Tests if a genre string is valid by searching for tracks with that genre. If no tracks are found, the genre is invalid.\n",
    "    \"\"\"\n",
    "    results = sp.search(q=f'genre:{genre}', type='track', limit=1)\n",
    "    number_of_tracks = len(results['tracks']['items'])\n",
    "    if number_of_tracks == 0:\n",
    "        print(f\"No tracks found for genre: {genre}\")\n",
    "        return False\n",
    "    else:\n",
    "        if debug:\n",
    "            print(f\"Found {number_of_tracks} tracks for genre: {genre}\")\n",
    "        return True\n",
    "    \n",
    "def get_genres_of_interest(genres_dict, genre_record_limit, pagination_limit=45, debug=False):\n",
    "    \"\"\"\n",
    "    Fetches track IDs for specified genres from Spotify, ensuring a balanced representation of each genre.\n",
    "    Args:\n",
    "        genres_dict (dict): A dictionary where keys are super genres and values are lists of sub-genres.\n",
    "        genre_record_limit (int): The maximum number of tracks to fetch per super genre.\n",
    "        pagination_limit (int, optional): The number of tracks to fetch per API call. Defaults to 45.\n",
    "        debug (bool, optional): If True, prints debug information. Defaults to False.\n",
    "    Returns:\n",
    "        tuple: A tuple containing two lists:\n",
    "            - track_ids (list): A list of track IDs fetched from Spotify.\n",
    "            - track_genre (list): A list of super genres corresponding to each track ID.\n",
    "    Raises:\n",
    "        AssertionError: If duplicate track IDs are found in the final list.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize variables\n",
    "    track_ids = []\n",
    "    track_genre = []\n",
    "    seen_track_ids = set()\n",
    "\n",
    "    for super_genre, sub_genres in genres_dict.items():\n",
    "        print(f\"Getting records for super genre: {super_genre}\")\n",
    "        super_genre_track_ids = []\n",
    "\n",
    "        # Dictionary to track how many tracks we pulled per sub-genre\n",
    "        sub_genre_counts = {sub_genre: 0 for sub_genre in sub_genres}\n",
    "\n",
    "        # Loop until we hit the genre_record_limit for the super genre\n",
    "        total_tracks_pulled = 0\n",
    "        \n",
    "        while total_tracks_pulled < genre_record_limit and sub_genres:\n",
    "            # Calculate remaining tracks needed for the super genre\n",
    "            tracks_needed = genre_record_limit - total_tracks_pulled\n",
    "\n",
    "            # Shuffle sub-genres to randomize the pulls\n",
    "            random.shuffle(sub_genres)\n",
    "\n",
    "            for sub_genre in sub_genres[:]:\n",
    "                \n",
    "                # Adjust the batch size to ensure we don't exceed the genre_record_limit\n",
    "                batch_size = min(pagination_limit, tracks_needed)\n",
    "\n",
    "                # Fetch a batch of tracks for the sub-genre\n",
    "                results = sp.search(q=f'genre:{sub_genre}', type='track', limit=batch_size, offset=sub_genre_counts[sub_genre])\n",
    "                \n",
    "                # If no items are returned, remove the sub-genre and move on\n",
    "                if not results['tracks']['items']:\n",
    "                    if debug:\n",
    "                        print(f\"No items for sub-genre: {sub_genre}, removing from sub-genres\")\n",
    "                    sub_genres.remove(sub_genre)  # Remove sub-genre if no more tracks are returned\n",
    "                    continue  # Skip the rest of the code for this sub-genre\n",
    "            \n",
    "                # Add new track IDs that are not already seen, but ensure we don't exceed the genre_record_limit\n",
    "                new_track_ids = [track['id'] for track in results['tracks']['items'] if track['id'] not in seen_track_ids]\n",
    "                new_tracks_needed = genre_record_limit - total_tracks_pulled\n",
    "                \n",
    "                # Only add as many tracks as needed to reach the limit\n",
    "                new_track_ids = new_track_ids[:new_tracks_needed]\n",
    "                \n",
    "                for track_id in new_track_ids:\n",
    "                    # Add the new track to the super genre's collection\n",
    "                    super_genre_track_ids.append(track_id)\n",
    "                    track_genre.append(super_genre)  # Label the track with the super genre\n",
    "                    seen_track_ids.add(track_id)\n",
    "                \n",
    "                # Update counts and totals\n",
    "                sub_genre_counts[sub_genre] += len(new_track_ids)\n",
    "                total_tracks_pulled += len(new_track_ids)\n",
    "\n",
    "                if debug:\n",
    "                    print(f\"Fetched {len(new_track_ids)} new tracks for sub-genre: {sub_genre}\")\n",
    "\n",
    "                # If we've reached the limit for the super genre, stop\n",
    "                if total_tracks_pulled >= genre_record_limit:\n",
    "                    break\n",
    "                \n",
    "            # Check again if we've exhausted all sub-genres\n",
    "            if not sub_genres:\n",
    "                if debug:\n",
    "                    print(f\"All sub-genres for super genre exhausted.\")\n",
    "                break\n",
    "\n",
    "        print(f\"{len(super_genre_track_ids)} records found for super genre: {super_genre}\\n\")\n",
    "        # Add the super genre track ids to the main list\n",
    "        track_ids.extend(super_genre_track_ids)\n",
    "\n",
    "    print(\"Total number of records:\", len(track_ids), \"\\n\")\n",
    "\n",
    "    # Check for duplicates in the final list\n",
    "    track_id_counts = Counter(track_ids)\n",
    "    duplicates = {track_id: count for track_id, count in track_id_counts.items() if count > 1}\n",
    "\n",
    "    # Assert no duplicates\n",
    "    assert not duplicates, f\"Duplicate track IDs found: {duplicates}\"\n",
    "\n",
    "    return track_ids, track_genre\n",
    "\n",
    "def get_other_genres(genres_of_interest, genre_record_limit, already_seen_ids, pagination_limit=45, debug=False):\n",
    "    \"\"\"\n",
    "    Fetches tracks from genres not included in the genres_of_interest.\n",
    "    Ensures an even distribution of tracks across genres and respects the genre_record_limit.\n",
    "    Args:\n",
    "        genres_of_interest (dict): A dictionary where keys are super genres and values are lists of sub-genres of interest.\n",
    "        genre_record_limit (int): The maximum number of tracks to fetch.\n",
    "        already_seen_ids (list or set): A list or set of track IDs that have already been gathered.\n",
    "        pagination_limit (int, optional): The number of tracks to fetch per API call. Defaults to 45.\n",
    "        debug (bool, optional): If True, prints debug information. Defaults to False.\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - other_track_ids (list): A list of track IDs from the 'other' genres.\n",
    "            - genre_labels (list): A list of genre labels corresponding to the fetched track IDs.\n",
    "            - genre_counts (dict): A dictionary with genres as keys and the count of fetched tracks as values.\n",
    "    Raises:\n",
    "        AssertionError: If duplicate track IDs are found in the final list of track IDs.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Getting 'other' genres.\")\n",
    "    already_seen_ids = set(already_seen_ids)  # Ensure it's a set for fast lookup\n",
    "\n",
    "    # Flatten the dictionary to get all sub-genres in genres_of_interest\n",
    "    sub_genres_of_interest = {sub_genre for super_genre, sub_genres in genres_of_interest.items() for sub_genre in sub_genres}\n",
    "\n",
    "    # All genres excluding genres_of_interest\n",
    "    other_genres = [genre for genre in sp.recommendation_genre_seeds()['genres'] if genre not in sub_genres_of_interest]\n",
    "\n",
    "    # Dictionary to track how many tracks we pulled per genre\n",
    "    genre_counts = {genre: 0 for genre in other_genres}\n",
    "\n",
    "    # List to hold unique track IDs for this function\n",
    "    other_track_ids = []\n",
    "\n",
    "    # Track total number of new tracks pulled\n",
    "    total_tracks_pulled = 0\n",
    "\n",
    "    # Loop until we hit the genre_record_limit\n",
    "    while total_tracks_pulled < genre_record_limit and other_genres:\n",
    "        # Calculate remaining tracks needed for the overall genre\n",
    "        tracks_needed = genre_record_limit - total_tracks_pulled\n",
    "\n",
    "        # Shuffle genres to randomize the pulls\n",
    "        random.shuffle(other_genres)\n",
    "\n",
    "        for genre in other_genres[:]:\n",
    "            # Adjust the batch size to ensure we don't exceed the genre_record_limit\n",
    "            batch_size = min(pagination_limit, tracks_needed)\n",
    "\n",
    "            # Fetch a batch of tracks for the genre\n",
    "            results = sp.search(q=f'genre:{genre}', type='track', limit=batch_size, offset=genre_counts[genre])\n",
    "\n",
    "            # If no items are returned, remove the genre and move on\n",
    "            if not results['tracks']['items']:\n",
    "                if debug:\n",
    "                    print(f\"No items for genre: {genre}, removing from other_genres\")\n",
    "                other_genres.remove(genre)\n",
    "                continue\n",
    "\n",
    "            # Add new track IDs that are not already seen, but ensure we don't exceed the genre_record_limit\n",
    "            new_track_ids = [track['id'] for track in results['tracks']['items'] if track['id'] not in already_seen_ids]\n",
    "            new_tracks_needed = genre_record_limit - total_tracks_pulled\n",
    "\n",
    "            # Only add as many tracks as needed to reach the limit\n",
    "            new_track_ids = new_track_ids[:new_tracks_needed]\n",
    "\n",
    "            for track_id in new_track_ids:\n",
    "                # Add the new track to the other track IDs collection\n",
    "                other_track_ids.append(track_id)\n",
    "                already_seen_ids.add(track_id)  # Also add to already seen IDs to avoid duplicates\n",
    "                genre_counts[genre] += 1\n",
    "                total_tracks_pulled += 1\n",
    "\n",
    "            if debug:\n",
    "                print(f\"Fetched {len(new_track_ids)} new tracks for genre: {genre}\")\n",
    "\n",
    "            # If we've reached the genre record limit, stop\n",
    "            if total_tracks_pulled >= genre_record_limit:\n",
    "                break\n",
    "\n",
    "    print(f\"Total number of new records: {len(other_track_ids)} new tracks\")\n",
    "\n",
    "    if debug:\n",
    "        # Print genre counts only for genres with tracks > 0\n",
    "        print(f\"\\nGenre Counts:\")\n",
    "        for genre, count in genre_counts.items():\n",
    "            if count > 0:\n",
    "                print(f\"{genre}: {count}\")\n",
    "\n",
    "    # Create genre labels for the new tracks\n",
    "    genre_labels = [\"other\"] * len(other_track_ids)\n",
    "\n",
    "    # Check for duplicates in the final list of track IDs\n",
    "    track_id_counts = Counter(other_track_ids)\n",
    "    duplicates = {track_id: count for track_id, count in track_id_counts.items() if count > 1}\n",
    "\n",
    "    # Assert no duplicates\n",
    "    assert not duplicates, f\"Duplicate track IDs found: {duplicates}\"\n",
    "\n",
    "    return other_track_ids, genre_labels, genre_counts\n",
    "\n",
    "def amend_sub_genres(sub_genres):\n",
    "    \"\"\"\n",
    "    Input: A list of sub-genres\n",
    "    Output: The same list with any sub-genres removed that do not return results from the Spotify API\n",
    "    \"\"\"\n",
    "    sub_genres = sub_genres.copy()\n",
    "    # Modify the sub_genres list in place\n",
    "    before = len(sub_genres)\n",
    "    print(f\"Number of sub genres before check: {before}\")\n",
    "    \n",
    "    # Create a copy of the list to avoid modifying it while iterating\n",
    "    for genre in sub_genres[:]:\n",
    "        if not test_genre_string(genre):\n",
    "            sub_genres.remove(genre)\n",
    "            print(f\"Removed {genre} from sub_genres.\")\n",
    "    \n",
    "    print(f\"Number of sub genres after check: {len(sub_genres)}, {before - len(sub_genres)} removed.\")\n",
    "    \n",
    "    return sub_genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Genres of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking sub-genres for rock\n",
      "Number of sub genres before check: 10\n",
      "Number of sub genres after check: 10, 0 removed.\n",
      "\n",
      "Checking sub-genres for pop\n",
      "Number of sub genres before check: 23\n",
      "Number of sub genres after check: 23, 0 removed.\n",
      "\n",
      "Checking sub-genres for rap/hip-hop\n",
      "Number of sub genres before check: 22\n",
      "No tracks found for genre: Lofi Hip Hop\n",
      "Removed Lofi Hip Hop from sub_genres.\n",
      "Number of sub genres after check: 21, 1 removed.\n",
      "\n",
      "Checking sub-genres for classical\n",
      "Number of sub genres before check: 22\n",
      "No tracks found for genre: Sacred Classical\n",
      "Removed Sacred Classical from sub_genres.\n",
      "No tracks found for genre: Cantata\n",
      "Removed Cantata from sub_genres.\n",
      "Number of sub genres after check: 20, 2 removed.\n",
      "\n",
      "Checking sub-genres for jazz\n",
      "Number of sub genres before check: 22\n",
      "No tracks found for genre: Modal Jazz\n",
      "Removed Modal Jazz from sub_genres.\n",
      "Number of sub genres after check: 21, 1 removed.\n"
     ]
    }
   ],
   "source": [
    "# Here you can add any string to any list in the dictionary. \n",
    "genres_of_interest = {\n",
    "    'rock': [\n",
    "            'rock',\n",
    "            'alt-rock',\n",
    "            'hard-rock',\n",
    "            'j-rock',\n",
    "            'psych-rock',\n",
    "            'punk-rock',\n",
    "            'rock-n-roll',\n",
    "            'rockabilly',\n",
    "            'grunge',\n",
    "            'punk'\n",
    "            ],\n",
    "    'pop': [\n",
    "            \"pop\",\n",
    "            \"Dance Pop\",\n",
    "            \"Electropop\",\n",
    "            \"Indie Pop\",\n",
    "            \"Synth-pop\",\n",
    "            \"Pop Rock\",\n",
    "            \"Teen Pop\",\n",
    "            \"Power Pop\",\n",
    "            \"Art Pop\",\n",
    "            \"Pop Punk\",\n",
    "            \"K-Pop\",\n",
    "            \"J-Pop\",\n",
    "            \"Latin Pop\",\n",
    "            \"Dream Pop\",\n",
    "            \"Bubblegum Pop\",\n",
    "            \"Euro Pop\",\n",
    "            \"Pop Rap\",\n",
    "            \"Chamber Pop\",\n",
    "            \"Baroque Pop\",\n",
    "            \"Pop Soul\",\n",
    "            \"Acoustic Pop\",\n",
    "            \"j-pop\",\n",
    "            \"k-pop\",\n",
    "            ],\n",
    "    'rap/hip-hop': [\n",
    "                \"Hip Hop\",\n",
    "                \"Hip-Hop\",\n",
    "                \"Rap\",\n",
    "                \"Trap\",\n",
    "                \"Gangsta Rap\",\n",
    "                \"East Coast Hip Hop\",\n",
    "                \"West Coast Hip Hop\",\n",
    "                \"Conscious Hip Hop\",\n",
    "                \"Alternative Hip Hop\",\n",
    "                \"Boom Bap\",\n",
    "                \"Dirty South\",\n",
    "                \"Crunk\",\n",
    "                \"Drill\",\n",
    "                \"Grime\",\n",
    "                \"Cloud Rap\",\n",
    "                \"Underground Hip Hop\",\n",
    "                \"Emo Rap\",\n",
    "                \"Hardcore Hip Hop\",\n",
    "                \"Lofi Hip Hop\",\n",
    "                \"Old School Hip Hop\",\n",
    "                \"Christian Hip Hop\",\n",
    "                \"Latin Hip Hop\"\n",
    "                ],\n",
    "    'classical': [\n",
    "                \"Classical\",\n",
    "                \"Baroque\",\n",
    "                \"Romantic\",\n",
    "                \"Classical\",\n",
    "                \"Chamber Music\",\n",
    "                \"Symphony\",\n",
    "                \"Opera\",\n",
    "                \"Choral\",\n",
    "                \"Contemporary Classical\",\n",
    "                \"Minimalism\",\n",
    "                \"Orchestral\",\n",
    "                \"Piano\",\n",
    "                \"String Quartet\",\n",
    "                \"Early Music\",\n",
    "                \"Renaissance\",\n",
    "                \"Modern Classical\",\n",
    "                \"Neoclassical\",\n",
    "                \"Impressionism\",\n",
    "                \"Avant-Garde\",\n",
    "                \"Sacred Classical\",\n",
    "                \"Cantata\",\n",
    "                \"Piano\"\n",
    "                ],\n",
    "    'jazz': [\n",
    "                \"Jazz\",\n",
    "                \"Bebop\",\n",
    "                \"Swing\",\n",
    "                \"Smooth Jazz\",\n",
    "                \"Cool Jazz\",\n",
    "                \"Hard Bop\",\n",
    "                \"Free Jazz\",\n",
    "                \"Fusion\",\n",
    "                \"Modal Jazz\",\n",
    "                \"Latin Jazz\",\n",
    "                \"Avant-Garde Jazz\",\n",
    "                \"Gypsy Jazz\",\n",
    "                \"Vocal Jazz\",\n",
    "                \"Jazz Funk\",\n",
    "                \"Jazz Blues\",\n",
    "                \"Soul Jazz\",\n",
    "                \"Post-Bop\",\n",
    "                \"Ragtime\",\n",
    "                \"Big Band\",\n",
    "                \"Dixieland\",\n",
    "                \"Nu Jazz\",\n",
    "                \"Jazz Fusion\",\n",
    "                ]\n",
    "}\n",
    "\n",
    "# This validates each string in the lists per super genre. If the string is not a recognized genre, it gets removed from the super genre list.\n",
    "\n",
    "for super_genre in genres_of_interest:\n",
    "    print(f\"\\nChecking sub-genres for {super_genre}\")\n",
    "    genres_of_interest[super_genre] = amend_sub_genres(genres_of_interest[super_genre])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Retrieval\n",
    "You can adjust the genre record limit, each super genre gets a maximum of genre_record_limit records.  \n",
    "Pagination is passed to the api as the limit parameter. Documentation says the max should be 50, but 45 seems to work best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_record_limit = 1500\n",
    "pagination_limit = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting records for super genre: rock\n",
      "1500 records found for super genre: rock\n",
      "\n",
      "Getting records for super genre: pop\n",
      "1500 records found for super genre: pop\n",
      "\n",
      "Getting records for super genre: rap/hip-hop\n",
      "1500 records found for super genre: rap/hip-hop\n",
      "\n",
      "Getting records for super genre: classical\n",
      "1500 records found for super genre: classical\n",
      "\n",
      "Getting records for super genre: jazz\n",
      "1500 records found for super genre: jazz\n",
      "\n",
      "Total number of records: 7500 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "track_ids, track_genre = get_genres_of_interest(genres_of_interest, genre_record_limit, pagination_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert length of track_ids is equal to genre_record_limit * number of super genres\n",
    "assert len(track_ids) == genre_record_limit * len(genres_of_interest), f\"Expected {genre_record_limit * len(genres_of_interest)} tracks, but got {len(track_ids)}\"\n",
    "\n",
    "# Assert no duplicates\n",
    "assert len(track_ids) == len(set(track_ids)), \"Duplicate tracks found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting 'other' genres.\n",
      "Total number of new records: 1500 new tracks\n"
     ]
    }
   ],
   "source": [
    "# Get other genres\n",
    "other_track_ids, other_genre_labels, other_genre_counts = get_other_genres(genres_of_interest, genre_record_limit, track_ids)\n",
    "\n",
    "# # This is helpful to see how many tracks were fetched for each super genre\n",
    "# for genre, count in other_genre_counts.items():\n",
    "#     if count > 0:\n",
    "#         print(f\"{genre}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two lists\n",
    "all_track_ids = track_ids + other_track_ids\n",
    "all_track_genre = track_genre + other_genre_labels\n",
    "\n",
    "# Create a DataFrame\n",
    "track_genres_df = pd.DataFrame({\"track_id\": all_track_ids, \"genre\": all_track_genre})\n",
    "\n",
    "# Assert no duplicates\n",
    "assert track_genres_df['track_id'].nunique() == len(track_genres_df), \"Duplicate track IDs found in the final DataFrame\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching audio features: 100%|██████████| 200/200 [00:30<00:00,  6.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get audio features for each track with a progress bar\n",
    "track_features = []\n",
    "for i in tqdm(range(0, len(track_genres_df), pagination_limit), desc=\"Fetching audio features\"):\n",
    "    features = sp.audio_features(all_track_ids[i:i+pagination_limit])\n",
    "    \n",
    "    # Raise error if no features are returned\n",
    "    if not features:\n",
    "        raise ValueError(f\"No audio features returned for tracks: {all_track_ids[i:i+pagination_limit]}\")\n",
    "    \n",
    "    for feature in features:\n",
    "        # Raise error if no features are returned for individual tracks\n",
    "        if not feature:\n",
    "            raise ValueError(f\"No audio features returned for track: {all_track_ids[i:i+pagination_limit]}\")\n",
    "        track_features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To DataFrame\n",
    "track_features_df = pd.DataFrame(track_features)\n",
    "# Rename id to track_id\n",
    "track_features_df.rename(columns={'id': 'track_id'}, inplace=True)\n",
    "\n",
    "# Assert no duplicates\n",
    "assert track_features_df['track_id'].nunique() == len(track_features_df), \"Duplicate track IDs found in the final DataFrame\"\n",
    "\n",
    "# Assert same length as track_genres_df\n",
    "assert len(track_features_df) == len(track_genres_df), \"Length of track_features_df and track_genres_df do not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames\n",
    "all_data = pd.merge(track_genres_df, track_features_df, on='track_id')\n",
    "\n",
    "# # Save the data\n",
    "# all_data.to_csv(\"spotify_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9000 entries, 44AyOl4qVkzS48vBsbNXaC to 3tHCG0ISOA0pXscIdNrJml\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   genre             9000 non-null   object \n",
      " 1   danceability      9000 non-null   float64\n",
      " 2   energy            9000 non-null   float64\n",
      " 3   key               9000 non-null   int64  \n",
      " 4   loudness          9000 non-null   float64\n",
      " 5   mode              9000 non-null   int64  \n",
      " 6   speechiness       9000 non-null   float64\n",
      " 7   acousticness      9000 non-null   float64\n",
      " 8   instrumentalness  9000 non-null   float64\n",
      " 9   liveness          9000 non-null   float64\n",
      " 10  valence           9000 non-null   float64\n",
      " 11  tempo             9000 non-null   float64\n",
      " 12  type              9000 non-null   object \n",
      " 13  uri               9000 non-null   object \n",
      " 14  track_href        9000 non-null   object \n",
      " 15  analysis_url      9000 non-null   object \n",
      " 16  duration_ms       9000 non-null   int64  \n",
      " 17  time_signature    9000 non-null   int64  \n",
      "dtypes: float64(9), int64(4), object(5)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('spotify_data.csv', index_col='track_id')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9000 entries, 44AyOl4qVkzS48vBsbNXaC to 3tHCG0ISOA0pXscIdNrJml\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   genre             9000 non-null   object \n",
      " 1   danceability      9000 non-null   float64\n",
      " 2   energy            9000 non-null   float64\n",
      " 3   key               9000 non-null   int64  \n",
      " 4   loudness          9000 non-null   float64\n",
      " 5   mode              9000 non-null   int64  \n",
      " 6   speechiness       9000 non-null   float64\n",
      " 7   acousticness      9000 non-null   float64\n",
      " 8   instrumentalness  9000 non-null   float64\n",
      " 9   liveness          9000 non-null   float64\n",
      " 10  valence           9000 non-null   float64\n",
      " 11  tempo             9000 non-null   float64\n",
      " 12  duration_ms       9000 non-null   int64  \n",
      " 13  time_signature    9000 non-null   int64  \n",
      "dtypes: float64(9), int64(4), object(1)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(['type', 'uri', 'track_href', 'analysis_url'], axis=1)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.duplicated().sum())\n",
    "print(data['track_id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial review shows our data has object and int/float columns. Object columns, aside from the genre, all can be dropped since they dont contribute to how genres are assigned. Int and float columns are labeled properly and can be used for training the model. There are no missing data and no duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list of attributes\n",
    "attributes = data.columns.drop('genre').tolist()\n",
    "\n",
    "# Violinplot of attributes per genre\n",
    "fig, axs = plt.subplots(2, 7, figsize=(20,10))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, attribute in enumerate(attributes):\n",
    "    sns.violinplot(data, x=attribute, y='genre', hue='genre', ax=axs[i])\n",
    "    # Remove labels for figures not in first column\n",
    "    if i % 7 != 0:\n",
    "        axs[i].set_ylabel('')\n",
    "        axs[i].set_yticks([])\n",
    "\n",
    "fig.delaxes(axs[-1])\n",
    "plt.suptitle('Distribution of Attributes per Genre', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually, we can see which attributes have a tendency to distiguish between genres (e.g. low energy score for classical music, higher speechiness for rap/hiphop), but we also want to verify if they are statistically different from each other per attribute so we can statistically determine whether to keep an attribute for the model training or not. If we were to just rely on visuals, we may drop key and mode due to indistinguishable differences, but let's use ANOVA to prove or disprove otherwise.\n",
    "\n",
    "We can also generate the grouped means of each attribute per genre to get a more numerical sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get grouped attribute means by genre\n",
    "grouped_means = data.groupby('genre').mean()\n",
    "grouped_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list for values\n",
    "attribute_stats = []\n",
    "\n",
    "# Perform ANOVA\n",
    "for attribute in attributes:\n",
    "    anova_results = stats.f_oneway(\n",
    "        data[data['genre'] == 'classical'][attribute],\n",
    "        data[data['genre'] == 'jazz'][attribute],\n",
    "        data[data['genre'] == 'pop'][attribute],\n",
    "        data[data['genre'] == 'rock'][attribute],\n",
    "        data[data['genre'] == 'rap/hip-hop'][attribute],\n",
    "        data[data['genre'] == 'other'][attribute],\n",
    "    )\n",
    "    \n",
    "    alpha = 0.05\n",
    "    if anova_results.pvalue < alpha:\n",
    "        attribute_stats.append([attribute, anova_results.statistic, anova_results.pvalue, 'Yes'])\n",
    "    else:\n",
    "        attribute_stats.append([attribute, nova_results.statistic, anova_results.pvalue, 'No'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_summary = pd.DataFrame(attribute_stats, columns=['Attribute', 'F-statistic', 'p-value', 'Significantly Different?'])\n",
    "attribute_summary = attribute_summary.set_index('Attribute')\n",
    "attribute_summary = attribute_summary.sort_values(by='F-statistic', ascending=False)\n",
    "attribute_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(attribute_summary, y='F-statistic', x='Attribute')\n",
    "plt.xticks(rotation=60)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the differences statistically, we can see based on the ANOVA test that there are some attributes that have more differences between each genre than the other, confirming what we were able to see visually in the violinplots. Additionally, the results of the key and mode attributes show that they are still significantly different per genre, although not as pronounced as the other attributes, but can still be used to distinguish between genres. All the attributes got a p-value less than 0.05, so we reject the null hypothesis that attributes per genre are not significantly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data.iloc[:,1:].corr()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, linewidths=0.5, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid multicollinearity, we may need to omit some features/attributes that have a high correlation coefficient. Coupling this information with the F-statistic results, it's best to keep the attribute with the highest F-statistic since it has a better ratio of variance between the grouped means and variance within the group. This gives the model a better gauge of distinction between the classes and should improve our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8100, 14)\n",
      "(900, 14)\n",
      "(8100, 13) (8100,)\n",
      "(900, 13) (900,)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, random_state=42)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "X_train = train.drop(['genre'], axis=1)\n",
    "y_train = train['genre']\n",
    "X_test = test.drop(['genre'], axis=1)\n",
    "y_test = test['genre']\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing KFold Instance\n",
    "cross_validator = KFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier(constant='rock', random_state=42, strategy='most_frequent') ROC_AUC: 0.5\n",
      "F1 of ROC_AUC model:  0.04257496923701276 \n",
      "\n",
      "DummyClassifier(constant='rock', random_state=42, strategy='uniform') F1: 0.1676583761097187\n",
      "ROC_AUC of F1 model:  0.5\n"
     ]
    }
   ],
   "source": [
    "# Creating Dummy model param grid\n",
    "dummy_params = {\n",
    "    'strategy':['most_frequent', 'prior', 'stratified', 'uniform', 'constant'],\n",
    "    'constant':['rock']\n",
    "}\n",
    "\n",
    "# Initializing DummyClassifier and its GridSearchCV\n",
    "dummy_model = DummyClassifier(random_state=42)\n",
    "dummy_grid_roc_auc = GridSearchCV(dummy_model, dummy_params, scoring='roc_auc_ovo_weighted', cv=cross_validator)\n",
    "dummy_grid_f1 = GridSearchCV(dummy_model, dummy_params, scoring='f1_weighted', cv=cross_validator)\n",
    "\n",
    "# Training Grid\n",
    "dummy_grid_roc_auc.fit(X_train, y_train)\n",
    "dummy_grid_f1.fit(X_train, y_train)\n",
    "dummy_f1 = cross_val_score(dummy_grid_roc_auc.best_estimator_, X_train, y_train, scoring='f1_weighted', cv=cross_validator).mean()\n",
    "dummy_roc_auc = cross_val_score(dummy_grid_f1.best_estimator_, X_train, y_train, scoring='roc_auc_ovo_weighted', cv=cross_validator).mean()\n",
    "\n",
    "\n",
    "print(dummy_grid_roc_auc.best_estimator_, f'ROC_AUC: {dummy_grid_roc_auc.best_score_}')\n",
    "print('F1 of ROC_AUC model: ', dummy_f1, '\\n')\n",
    "print(dummy_grid_f1.best_estimator_, f'F1: {dummy_grid_f1.best_score_}')\n",
    "print('ROC_AUC of F1 model: ', dummy_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=7, min_samples_split=6, random_state=42) ROC_AUC: 0.7844794389067227\n",
      "F1 of ROC_AUC model:  0.48894107684397276 \n",
      "\n",
      "DecisionTreeClassifier(max_depth=9, min_samples_split=6, random_state=42) F1: 0.49247320622517093\n",
      "ROC_AUC of F1 model:  0.7702834658469125\n"
     ]
    }
   ],
   "source": [
    "# Creating DecisionTree model param grid\n",
    "tree_params = {\n",
    "    'max_depth':np.arange(3, 11, 1),\n",
    "    'min_samples_split':[2,4,6]\n",
    "}\n",
    "\n",
    "# Initializing DecisionTree and its GridSearchCV\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "tree_grid_roc_auc = GridSearchCV(tree_model, tree_params, scoring='roc_auc_ovo_weighted', cv=cross_validator)\n",
    "tree_grid_f1 = GridSearchCV(tree_model, tree_params, scoring='f1_weighted', cv=cross_validator)\n",
    "\n",
    "# Training Grid\n",
    "tree_grid_roc_auc.fit(X_train, y_train)\n",
    "tree_grid_f1.fit(X_train, y_train)\n",
    "tree_f1 = cross_val_score(tree_grid_roc_auc.best_estimator_, X_train, y_train, scoring='f1_weighted', cv=cross_validator).mean()\n",
    "tree_roc_auc = cross_val_score(tree_grid_f1.best_estimator_, X_train, y_train, scoring='roc_auc_ovo_weighted', cv=cross_validator).mean()\n",
    "\n",
    "print(tree_grid_roc_auc.best_estimator_, f'ROC_AUC: {tree_grid_roc_auc.best_score_}')\n",
    "print('F1 of ROC_AUC model: ', tree_f1, '\\n')\n",
    "print(tree_grid_f1.best_estimator_, f'F1: {tree_grid_f1.best_score_}')\n",
    "print('ROC_AUC of F1 model: ', tree_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=22, n_estimators=1500, random_state=42) ROC_AUC: 0.8656457394367386\n",
      "F1 of ROC_AUC model:  0.5755083909317781 \n",
      "\n",
      "RandomForestClassifier(max_depth=22, n_estimators=1500, random_state=42) F1: 0.5755083909317781\n",
      "ROC_AUC of F1 model:  0.7702834658469125\n"
     ]
    }
   ],
   "source": [
    "# Creating RandomForest model param grid\n",
    "forest_params = {\n",
    "    'n_estimators':[500, 1000, 1500],\n",
    "    'max_depth':np.arange(20, 41, 2),\n",
    "}\n",
    "\n",
    "# Initializing RandomForest and its GridSearchCV\n",
    "forest_model = RandomForestClassifier(random_state=42)\n",
    "forest_grid_roc_auc = GridSearchCV(forest_model, forest_params, scoring='roc_auc_ovo_weighted', cv=cross_validator)\n",
    "forest_grid_f1 = GridSearchCV(forest_model, forest_params, scoring='f1_weighted', cv=cross_validator)\n",
    "\n",
    "# Training Grid\n",
    "forest_grid_roc_auc.fit(X_train, y_train)\n",
    "forest_grid_f1.fit(X_train, y_train)\n",
    "forest_f1 = cross_val_score(forest_grid_roc_auc.best_estimator_, X_train, y_train, scoring='f1_weighted', cv=cross_validator).mean()\n",
    "forest_roc_auc = cross_val_score(forest_grid_f1.best_estimator_, X_train, y_train, scoring='roc_auc_ovo_weighted', cv=cross_validator).mean()\n",
    "\n",
    "print(forest_grid_roc_auc.best_estimator_, f'ROC_AUC: {forest_grid_roc_auc.best_score_}')\n",
    "print('F1 of ROC_AUC model: ', forest_f1, '\\n')\n",
    "print(forest_grid_f1.best_estimator_, f'F1: {forest_grid_f1.best_score_}')\n",
    "print('ROC_AUC of F1 model: ', forest_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.01, num_leaves=100, random_state=42,\n",
      "               verbosity=-1) ROC_AUC: 0.8431479275343451\n",
      "F1 of ROC_AUC model:  0.5523200542615104 \n",
      "\n",
      "LGBMClassifier(learning_rate=0.01, num_leaves=200, random_state=42,\n",
      "               verbosity=-1) F1: 0.5565323696002716\n",
      "ROC_AUC of F1 model:  0.8430191651830828\n"
     ]
    }
   ],
   "source": [
    "# Creating LightGBM model param grid\n",
    "lightgbm_params = {\n",
    "    'num_leaves':[31, 100, 200],\n",
    "    'learning_rate':[0.01]\n",
    "}\n",
    "\n",
    "# Initializing LightGBM and its GridSearchCV\n",
    "lightgbm_model = lgb.LGBMClassifier(random_state=42, verbosity=-1)\n",
    "lightgbm_grid_roc_auc = GridSearchCV(lightgbm_model, lightgbm_params, scoring='roc_auc_ovo_weighted', cv=cross_validator)\n",
    "lightgbm_grid_f1 = GridSearchCV(lightgbm_model, lightgbm_params, scoring='f1_weighted', cv=cross_validator)\n",
    "\n",
    "# Training Grid\n",
    "lightgbm_grid_roc_auc.fit(X_train, y_train)\n",
    "lightgbm_grid_f1.fit(X_train, y_train)\n",
    "lightgbm_f1 = cross_val_score(lightgbm_grid_roc_auc.best_estimator_, X_train, y_train, scoring='f1_weighted', cv=cross_validator).mean()\n",
    "lightgbm_roc_auc = cross_val_score(lightgbm_grid_f1.best_estimator_, X_train, y_train, scoring='roc_auc_ovo_weighted', cv=cross_validator).mean()\n",
    "\n",
    "print(lightgbm_grid_roc_auc.best_estimator_, f'ROC_AUC: {lightgbm_grid_roc_auc.best_score_}')\n",
    "print('F1 of ROC_AUC model: ', lightgbm_f1, '\\n')\n",
    "print(lightgbm_grid_f1.best_estimator_, f'F1: {lightgbm_grid_f1.best_score_}')\n",
    "print('ROC_AUC of F1 model: ', lightgbm_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.7825969\ttotal: 10.6ms\tremaining: 10.6s\n",
      "1000:\tlearn: 0.9863546\ttotal: 9.21s\tremaining: 0us\n",
      "0:\tlearn: 1.7827187\ttotal: 44.7ms\tremaining: 44.7s\n",
      "1000:\tlearn: 0.9912005\ttotal: 9.07s\tremaining: 0us\n",
      "0:\tlearn: 1.7832833\ttotal: 42.1ms\tremaining: 42.1s\n",
      "1000:\tlearn: 0.9852248\ttotal: 9.09s\tremaining: 0us\n",
      "0:\tlearn: 1.7825969\ttotal: 16.8ms\tremaining: 33.7s\n",
      "1000:\tlearn: 0.9863546\ttotal: 9s\tremaining: 8.99s\n",
      "2000:\tlearn: 0.8357130\ttotal: 17.9s\tremaining: 0us\n",
      "0:\tlearn: 1.7827187\ttotal: 10.3ms\tremaining: 20.5s\n",
      "1000:\tlearn: 0.9912005\ttotal: 9.01s\tremaining: 9s\n",
      "2000:\tlearn: 0.8355803\ttotal: 18s\tremaining: 0us\n",
      "0:\tlearn: 1.7832833\ttotal: 33.8ms\tremaining: 1m 7s\n",
      "1000:\tlearn: 0.9852248\ttotal: 9.13s\tremaining: 9.13s\n",
      "2000:\tlearn: 0.8346204\ttotal: 19.2s\tremaining: 0us\n",
      "0:\tlearn: 1.7820866\ttotal: 13.9ms\tremaining: 27.8s\n",
      "1000:\tlearn: 1.0167922\ttotal: 9.78s\tremaining: 9.77s\n",
      "2000:\tlearn: 0.8863225\ttotal: 20.9s\tremaining: 0us\n",
      "0:\tlearn: 1.7825969\ttotal: 50.1ms\tremaining: 50.1s\n",
      "1000:\tlearn: 0.9863546\ttotal: 9.36s\tremaining: 0us\n",
      "0:\tlearn: 1.7827187\ttotal: 10.5ms\tremaining: 10.5s\n",
      "1000:\tlearn: 0.9912005\ttotal: 9.15s\tremaining: 0us\n",
      "0:\tlearn: 1.7832833\ttotal: 14.6ms\tremaining: 14.6s\n",
      "1000:\tlearn: 0.9852248\ttotal: 9.09s\tremaining: 0us\n",
      "0:\tlearn: 1.7825969\ttotal: 11.5ms\tremaining: 22.9s\n",
      "1000:\tlearn: 0.9863546\ttotal: 9.07s\tremaining: 9.06s\n",
      "2000:\tlearn: 0.8357130\ttotal: 18s\tremaining: 0us\n",
      "0:\tlearn: 1.7827187\ttotal: 41.7ms\tremaining: 1m 23s\n",
      "1000:\tlearn: 0.9912005\ttotal: 10.3s\tremaining: 10.3s\n",
      "2000:\tlearn: 0.8355803\ttotal: 19.3s\tremaining: 0us\n",
      "0:\tlearn: 1.7832833\ttotal: 16.1ms\tremaining: 32.2s\n",
      "1000:\tlearn: 0.9852248\ttotal: 9.18s\tremaining: 9.17s\n",
      "2000:\tlearn: 0.8346204\ttotal: 18.1s\tremaining: 0us\n",
      "0:\tlearn: 1.7820866\ttotal: 12.4ms\tremaining: 24.8s\n",
      "1000:\tlearn: 1.0167922\ttotal: 10.1s\tremaining: 10.1s\n",
      "2000:\tlearn: 0.8863225\ttotal: 19.7s\tremaining: 0us\n",
      "0:\tlearn: 1.7825969\ttotal: 12.4ms\tremaining: 24.8s\n",
      "1000:\tlearn: 0.9863546\ttotal: 9.01s\tremaining: 9s\n",
      "2000:\tlearn: 0.8357130\ttotal: 18s\tremaining: 0us\n",
      "0:\tlearn: 1.7827187\ttotal: 31.7ms\tremaining: 1m 3s\n",
      "1000:\tlearn: 0.9912005\ttotal: 9.58s\tremaining: 9.57s\n",
      "2000:\tlearn: 0.8355803\ttotal: 19s\tremaining: 0us\n",
      "0:\tlearn: 1.7832833\ttotal: 17.4ms\tremaining: 34.8s\n",
      "1000:\tlearn: 0.9852248\ttotal: 9s\tremaining: 8.99s\n",
      "2000:\tlearn: 0.8346204\ttotal: 18.3s\tremaining: 0us\n",
      "0:\tlearn: 1.7825969\ttotal: 10.5ms\tremaining: 21.1s\n",
      "1000:\tlearn: 0.9863546\ttotal: 9.82s\tremaining: 9.81s\n",
      "2000:\tlearn: 0.8357130\ttotal: 18.6s\tremaining: 0us\n",
      "0:\tlearn: 1.7827187\ttotal: 25ms\tremaining: 50s\n",
      "1000:\tlearn: 0.9912005\ttotal: 9.06s\tremaining: 9.05s\n",
      "2000:\tlearn: 0.8355803\ttotal: 17.8s\tremaining: 0us\n",
      "0:\tlearn: 1.7832833\ttotal: 15.6ms\tremaining: 31.2s\n",
      "1000:\tlearn: 0.9852248\ttotal: 9.08s\tremaining: 9.07s\n",
      "2000:\tlearn: 0.8346204\ttotal: 18.1s\tremaining: 0us\n",
      "<catboost.core.CatBoostClassifier object at 0x0000019CE5FA1810> ROC_AUC: 0.8602144547482479\n",
      "F1 of ROC_AUC model:  0.566502298583798 \n",
      "\n",
      "<catboost.core.CatBoostClassifier object at 0x0000019CE82BBB50> F1: 0.566502298583798\n",
      "ROC_AUC of F1 model:  0.8602144547482479\n"
     ]
    }
   ],
   "source": [
    "# Creating CatBoost model param grid\n",
    "catboost_params = {\n",
    "    'iterations':[1001, 2001],\n",
    "    'learning_rate':[0.01]\n",
    "}\n",
    "\n",
    "# Initializing CatBoost and its GridSearchCV\n",
    "catboost_model = CatBoostClassifier(random_seed=42, verbose=1000)\n",
    "catboost_grid_roc_auc = GridSearchCV(catboost_model, catboost_params, scoring='roc_auc_ovo_weighted', cv=cross_validator)\n",
    "catboost_grid_f1 = GridSearchCV(catboost_model, catboost_params, scoring='f1_weighted', cv=cross_validator)\n",
    "\n",
    "# Training Grid\n",
    "catboost_grid_roc_auc.fit(X_train, y_train)\n",
    "catboost_grid_f1.fit(X_train, y_train)\n",
    "catboost_f1 = cross_val_score(catboost_grid_roc_auc.best_estimator_, X_train, y_train, scoring='f1_weighted', cv=cross_validator).mean()\n",
    "catboost_roc_auc = cross_val_score(catboost_grid_f1.best_estimator_, X_train, y_train, scoring='roc_auc_ovo_weighted', cv=cross_validator).mean()\n",
    "\n",
    "\n",
    "print(catboost_grid_roc_auc.best_estimator_, f'ROC_AUC: {catboost_grid_roc_auc.best_score_}')\n",
    "print('F1 of ROC_AUC model: ', catboost_f1, '\\n')\n",
    "print(catboost_grid_f1.best_estimator_, f'F1: {catboost_grid_f1.best_score_}')\n",
    "print('ROC_AUC of F1 model: ', catboost_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=22, n_estimators=1500, random_state=42) Test ROC_AUC: 0.8818380990339227\n",
      "F1 of ROC_AUC model:  0.6007459537175455 \n",
      "\n",
      "RandomForestClassifier(max_depth=22, n_estimators=1500, random_state=42) Test F1: 0.6007459537175455\n",
      "ROC_AUC of F1 model:  0.8818380990339227\n"
     ]
    }
   ],
   "source": [
    "test_roc_auc_predict = forest_grid_roc_auc.best_estimator_.predict(X_test)\n",
    "test_roc_auc_proba = forest_grid_roc_auc.best_estimator_.predict_proba(X_test)\n",
    "test_f1_predict = forest_grid_f1.best_estimator_.predict(X_test)\n",
    "test_f1_proba = forest_grid_f1.best_estimator_.predict_proba(X_test)\n",
    "\n",
    "test_roc_auc = metrics.roc_auc_score(y_test, test_roc_auc_proba, average='weighted', multi_class='ovo')\n",
    "test_roc_auc_f1 = metrics.f1_score(y_test, test_roc_auc_predict, average='weighted')\n",
    "test_f1 = metrics.f1_score(y_test, test_f1_predict, average='weighted')\n",
    "test_f1_roc_auc = metrics.roc_auc_score(y_test, test_f1_proba, average='weighted', multi_class='ovo')\n",
    "    \n",
    "\n",
    "\n",
    "print(forest_grid_roc_auc.best_estimator_, f'Test ROC_AUC: {test_roc_auc}')\n",
    "print('F1 of ROC_AUC model: ', test_roc_auc_f1, '\\n')\n",
    "print(forest_grid_f1.best_estimator_, f'Test F1: {test_f1}')\n",
    "print('ROC_AUC of F1 model: ', test_f1_roc_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
